# -*- coding: utf-8 -*-
"""Untitled13.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1s8pcDZu4AxRiHaYUTwHBkPB5T_LjWtJe
"""

from google.colab import drive
drive.mount('/content/drive')

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import seaborn as sns
import matplotlib.pyplot as plt

import os


# Any results you write to the current directory are saved as output.

# Load the data directly
sales = pd.read_csv('/content/drive/MyDrive/cal/supermarket_sales_assignment1.csv')

# Display the first few rows of the DataFrame
sales.head()

# This shows how the real data looks when it is feed to the algo for predection

#Loading the data into the pandas data frame is certainly one of the most important steps in EDA, as we can see that the value from the data set is comma-separated.
# So all we have to do is to just read the CSV into a data frame and pandas data frame does the job for us.

sales.info()

# Get the data types of each column
data_types = sales.dtypes


# Get the total null values for each column
total_null_values = sales.isnull().sum()

# Combine all information into a DataFrame for better visualization
data_info = pd.DataFrame({

    'Total Null Count': total_null_values
})

# Display the data information
print("Number of rows:", num_rows)
print("Number of columns:", num_cols)
print(data_info)

sales.drop(columns=["gross margin percentage"],inplace=True)

#after remove  gross margin percentage  colum then i view
sales.head()

sales['Date'] = pd.to_datetime(sales['Date'])
sales['Time'] = pd.to_datetime(sales['Time'])

sales.shape

duplicate_rows_df = sales[sales.duplicated()]
print("number of duplicate rows: ", duplicate_rows_df.shape)

#Now let us remove the duplicate data because it's ok to remove them.

sales.count()      # Used to count the number of rows

#So seen above there are 1000 rows and we are removing 2 rows of duplicate data.


sales = sales.drop_duplicates()
sales.head(5)

#after remvoe duplicate rows
sales.count()

print(sales.isnull().sum())

sales = sales.dropna()    # Dropping the missing values.
sales.count()

#Now we have removed all the rows which contain the Null or N/A values Unit price ,Tax  ,Total gross income   .

sns.boxplot(x=sales['Rating']).set_title(" by Rating")

sns.boxplot(x=sales['gross income']).set_title(" by gross income")

sns.boxplot(x=sales['cogs']).set_title(" by cogs")

# Select only numeric columns for calculating quantiles and IQR
numeric_columns = sales.select_dtypes(include=[np.number])

# Calculate quartiles
Q1 = numeric_columns.quantile(0.25)
Q3 = numeric_columns.quantile(0.75)

# Calculate IQR
IQR = Q3 - Q1

print("Interquartile range for each numeric column:")
print(IQR)

plt.pie(sales['Gender'].value_counts(),labels= sales['Gender'].value_counts(),shadow=True)
plt.legend(sales['Gender'].unique())
plt.title("Proportion of each gender as customers")
plt.show()

# Count the number of items by product line
product_line_counts = sales['Product line'].value_counts()

# Plotting
plt.figure(figsize=(6, 6))
sns.barplot(x=product_line_counts.index, y=product_line_counts.values, palette="viridis")
plt.title('Number of Items by Product Line')
plt.xlabel('Product Line')
plt.ylabel('Number of Items')
plt.xticks(rotation=45, ha='right')  # Rotate x labels for better readability
plt.show()